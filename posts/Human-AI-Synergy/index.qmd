---
title: "Why Human + AI Is Not Always Better"
author: "Yonas Gebre"
date: "2026-01-12"
categories: [ai, data-science, analysis]
bibliography: references.bib
---

## Introduction

Artificial intelligence (AI) is often described as a tool that makes people smarter, faster, and more productive. From writing emails to recommending medical diagnoses, AI systems are designed to support human decision-making. It feels natural to assume that combining human judgment with AI predictions should always lead to better results than either working alone.

This belief is widespread. Many organizations now design systems with “humans in the loop,” assuming that human oversight will catch AI’s mistakes while AI will compensate for human limitations. In theory, this sounds like the best of both worlds.

However, recent research suggests that this assumption is too simple  [@vaccaro2024humanai]. While AI often helps people perform better, combining humans and AI does not always lead to the best outcomes. In fact, under certain conditions, human–AI teams perform worse than humans or AI working alone (@vaccaro2024humanai). Understanding why this happens is important for anyone who uses AI tools in school, work, or everyday life.



## What Research Shows About Human–AI Collaboration

To better understand how humans and AI perform together, the researchers compared human–AI systems against clear baselines, or reference points, for performance.

In each experiment, they first identified how well humans performed on their own and how well the AI performed on its own. Whichever of these two performed better was treated as the strongest baseline. The researchers then asked a strict question: Does combining humans and AI perform better than the best option available? This comparison captures whether true human–AI synergy is achieved.

They also made a second, simpler comparison using a different baseline: humans working alone. Here, the question was Does AI help people perform better than they would on their own? This comparison focuses on human augmentation, even if the combined system is not the best overall performer.

By applying these baseline comparisons across hundreds of experiments and many different tasks, such as content creation, problem solving, and image classification, the researchers were able to identify consistent patterns in human–AI collaboration. The figure below summarizes the results of these two baseline comparisons.

![](HumanAISynergy.png){fig-align="center" width="80%"}

The right panel shows that AI usually helps humans. In most of the experiments analyzed, people performed better when they received assistance from an AI system than when they worked alone.

The left panel shows a more surprising result. In more than half of the experiments, human–AI teams performed worse than the better of humans or AI working alone. This indicates that although AI often improves human performance, human–AI synergy is not consistently achieved.

Together, these results reveal an important insight: *While AI systems oftem make humans better, **human–AI synergy is not always achieved in practice** *. 



## Why Working With AI Can Make Results Worse

Understanding why human–AI collaboration sometimes fails requires looking beyond the technology itself and focusing on how people interact with AI systems. While AI models may be highly accurate on their own, the way humans interpret, trust, and act on AI outputs plays a major role in determining whether collaboration improves or harms performance.


### People Struggle to Use AI Correctly

One major reason collaboration fails is that people struggle to judge when to trust AI. Sometimes people trust AI too much and follow its suggestions even when they are incorrect. Other times, people distrust AI and ignore helpful advice. These behaviors are common and predictable.

For example, if an AI system has been accurate in the past, people may treat its output as authoritative and stop thinking critically. When the AI makes a mistake, the human simply follows along. On the other hand, if people feel uncomfortable with automation, they may reject AI suggestions altogether, even when the AI is right.

These patterns are not random errors. They reflect how humans naturally respond to automated systems. As a result, human–AI teams can repeatedly make the same types of mistakes, leading to worse overall performance.


### The Type of Task Matters

Another key factor that shapes human–AI collaboration is the **type of task** being performed. Across many experiments, researchers consistently found that collaboration works differently for creative tasks than for decision-making tasks.

For creative tasks such as writing, designing, or brainstorming, human–AI collaboration tends to work better. In a large share of the studies involving these tasks, humans benefited from AI support. This is likely because creative work naturally allows a division of roles. Humans contribute ideas, context, and judgment, while AI helps with routine or repetitive parts, such as generating drafts or filling in details.

In contrast, for decision tasks where deliberate thinking is required, or choosing the correct answer, collaboration often works worse. In many of these experiments, human–AI teams performed worse than the best option working alone. These tasks typically require both the human and the AI to make a full decision, which makes coordination difficult. Instead of complementing each other, humans and AI can interfere with one another’s strengths.


### Skill Differences Between Humans and AI

The effectiveness of collaboration also depends on **who performs better when working alone**. Across the experiments analyzed, researchers observed a clear pattern based on relative skill.

When AI outperformed humans on a task, adding human judgment often reduced overall performance. In many such experiments, people struggled to know when to trust the AI and when to rely on their own judgment. This led them to override correct AI predictions or introduce new errors.

When humans performed better than AI, collaboration tended to improve results. In these cases, people were more successful at deciding when AI input was useful and when it should be ignored. This suggests that successful human–AI collaboration depends not only on accuracy, but also on people’s ability to manage the interaction effectively.



## Why This Matters in Real Life

These findings have important implications for how we use AI in everyday settings. Many students use AI tools to study or complete assignments. Professionals rely on AI recommendations in fields such as healthcare, finance, and hiring. In all these cases, simply adding AI to the workflow does not guarantee better results.

For tasks that require careful decision-making, it may be better to rely on either human judgment or AI alone, rather than combining them without clear roles. For creative or exploratory tasks, AI can be a powerful assistant when used as a tool rather than a decision-maker.

The key lesson is that effective human–AI collaboration requires thoughtful design. People need guidance on how and when to use AI, and systems should be built so that humans and AI focus on what they each do best.



## Conclusion

AI is a powerful tool, and in many cases, it improves human performance. However, research shows that combining humans and AI does not automatically lead to better outcomes. Collaboration can fail when people misuse AI, when tasks are poorly designed, or when skill differences are not taken into account.

Rather than assuming that “human plus AI” is always better, we should think more deeply about how collaboration with these systems is designed. Successful use of AI is not just a technological problem, it is a design and communication problem. How we choose to work with AI matters just as much as how accurate it is.
